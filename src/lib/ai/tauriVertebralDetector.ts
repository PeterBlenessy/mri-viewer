import { invoke } from '@tauri-apps/api/core'
import { DicomInstance } from '@/types'
import { MarkerAnnotation } from '@/types/annotation'
import { DetectionResult } from './mockVertebralDetector'

/**
 * Vertebra structure from Python API
 */
interface Vertebra {
  label: string
  center: {
    x: number
    y: number
    z: number
  }
  confidence: number
}

/**
 * Response from Python AI server
 */
interface VertebraeResult {
  success: boolean
  vertebrae: Vertebra[]
  processing_time_ms: number
  error?: string
}

/**
 * Server status from Rust
 */
interface ServerStatus {
  running: boolean
  port: number
  version: string
}

/**
 * Tauri-based vertebral detector using Python sidecar
 * Calls real TotalSegmentator AI model via Tauri IPC
 */
export class TauriVertebralDetector {
  private serverChecked = false

  /**
   * Ensure AI server is running
   */
  private async ensureServerRunning(): Promise<void> {
    if (this.serverChecked) {
      // Verify it's still running
      try {
        const status = await invoke<ServerStatus>('get_server_status')
        if (status.running) return
        console.log('[TauriDetector] Server was running but stopped, restarting...')
        this.serverChecked = false // Force restart
      } catch (error) {
        console.warn('[TauriDetector] Status check failed, will attempt restart')
        this.serverChecked = false
      }
    }

    try {
      const status = await invoke<ServerStatus>('get_server_status')

      if (!status.running) {
        console.log('[TauriDetector] AI server not running, starting...')
        const startStatus = await invoke<ServerStatus>('start_ai_server')
        console.log(`[TauriDetector] AI server started successfully on port ${startStatus.port}`)

        // Wait a bit more for server to fully initialize
        await new Promise(resolve => setTimeout(resolve, 2000))

        // Verify server is responding
        const verifyStatus = await invoke<ServerStatus>('get_server_status')
        if (!verifyStatus.running) {
          throw new Error('Server reported as started but status check failed')
        }
      } else {
        console.log('[TauriDetector] AI server already running on port ' + status.port)
      }

      this.serverChecked = true
    } catch (error) {
      this.serverChecked = false
      console.error('[TauriDetector] Failed to ensure server running:', error)
      throw new Error(`AI server unavailable: ${error}`)
    }
  }

  /**
   * Convert Python vertebra to annotation
   */
  private convertToAnnotation(
    vertebra: Vertebra,
    instance: DicomInstance,
    index: number
  ): MarkerAnnotation {
    return {
      id: `ai-${instance.sopInstanceUID}-${vertebra.label}-${Date.now()}-${index}`,
      type: 'marker',
      seriesInstanceUID: instance.metadata?.seriesDescription || '',
      sopInstanceUID: instance.sopInstanceUID,
      instanceNumber: instance.instanceNumber,
      severity: 'normal',
      description: `AI-detected ${vertebra.label} vertebra (confidence: ${(vertebra.confidence * 100).toFixed(1)}%)`,
      createdAt: new Date().toISOString(),
      createdBy: 'TotalSegmentator-AI',
      autoGenerated: true,
      modelVersion: 'TotalSegmentator-v2',
      position: {
        x: vertebra.center.x,
        y: vertebra.center.y,
      },
      label: vertebra.label,
    }
  }

  /**
   * Detect vertebrae in a DICOM image using real AI
   */
  async detectVertebrae(instance: DicomInstance): Promise<DetectionResult> {
    const startTime = performance.now()

    // Ensure server is running
    await this.ensureServerRunning()

    // Get the file path from the instance
    // In Tauri, we need the actual file path on disk
    const filePath = instance.filePath

    if (!filePath) {
      throw new Error(
        'File path not available. DICOM files must be loaded from disk using folder picker in desktop mode.'
      )
    }

    console.log(`[TauriDetector] Detecting vertebrae in: ${filePath}`)

    try {
      // Call Rust command which forwards to Python API
      // Add retry logic in case server needs more time
      let lastError: any
      const maxRetries = 2

      for (let attempt = 1; attempt <= maxRetries; attempt++) {
        try {
          console.log(`[TauriDetector] Attempt ${attempt}/${maxRetries}`)

          const result = await invoke<VertebraeResult>('detect_vertebrae', {
            filePath: filePath,
          })

          if (!result.success) {
            throw new Error(result.error || 'Detection failed')
          }

          console.log(
            `[TauriDetector] Success! Detected ${result.vertebrae.length} vertebrae ` +
            `in ${result.processing_time_ms}ms (attempt ${attempt})`
          )

          // Convert to annotations
          const annotations = result.vertebrae.map((vertebra, index) =>
            this.convertToAnnotation(vertebra, instance, index)
          )

          // Calculate average confidence
          const avgConfidence = result.vertebrae.length > 0
            ? result.vertebrae.reduce((sum, v) => sum + v.confidence, 0) / result.vertebrae.length
            : 0

          const totalTime = performance.now() - startTime

          return {
            annotations,
            confidence: avgConfidence,
            processingTimeMs: totalTime,
          }
        } catch (err) {
          lastError = err
          console.warn(`[TauriDetector] Attempt ${attempt} failed:`, err)

          if (attempt < maxRetries) {
            console.log('[TauriDetector] Waiting 3s before retry...')
            await new Promise(resolve => setTimeout(resolve, 3000))

            // Check if server is still running
            const status = await invoke<ServerStatus>('get_server_status')
            if (!status.running) {
              console.error('[TauriDetector] Server stopped, restarting...')
              this.serverChecked = false
              await this.ensureServerRunning()
            }
          }
        }
      }

      throw lastError
    } catch (error) {
      console.error('[TauriDetector] All attempts failed:', error)
      throw new Error(`AI detection failed: ${error}`)
    }
  }

  /**
   * Check if AI server is running
   */
  async checkServerStatus(): Promise<ServerStatus> {
    return invoke<ServerStatus>('get_server_status')
  }

  /**
   * Stop AI server (for cleanup)
   */
  async stopServer(): Promise<void> {
    await invoke('stop_ai_server')
  }
}

// Export singleton instance
export const tauriDetector = new TauriVertebralDetector()
